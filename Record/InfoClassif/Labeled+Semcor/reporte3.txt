Orden:
MLPClassifier,SVM,LogisticRegression,LinearDiscriminantAnalysis,KNeighborsClassifier,DecisionTreeClassifier,GaussianNB,SGDClassifier,RandomForestClassifier

Accuracy

I) NO NORMALIZACION Y NO REDUCCION
0.687 (+/-0.203) for {'learning_rate': 'constant', 'solver': 'adam', 'alpha': 0.1, 'random_state': 42, 'activation': 'tanh', 'hidden_layer_sizes': 12}
0.690 (+/-0.204) for {'kernel': 'rbf', 'gamma': 0.01, 'random_state': 0, 'probability': True, 'C': 1}
0.675 (+/-0.239) for {'random_state': 0, 'C': 0.1}
0.668 (+/-0.208) for {'solver': 'svd'}
0.626 (+/-0.179) for {'weights': 'distance', 'n_neighbors': 15, 'algorithm': 'auto'}
0.616 (+/-0.133) for {'random_state': 0, 'criterion': 'entropy', 'splitter': 'best', 'max_features': None}
0.608 (+/-0.208) for {'priors': None}
0.682 (+/-0.234) for {'loss': 'modified_huber', 'epsilon': 0.01, 'random_state': 0, 'alpha': 1}
0.671 (+/-0.201) for {'random_state': 0, 'criterion': 'entropy', 'n_estimators': 30, 'max_features': None}


II) NOMRALIZACION
0.675 (+/-0.162) for {'activation': 'tanh', 'alpha': 1, 'learning_rate': 'constant', 'solver': 'adam', 'hidden_layer_sizes': 12, 'random_state': 42}
0.657 (+/-0.208) for {'gamma': 0.01, 'random_state': 0, 'C': 1, 'probability': True, 'kernel': 'rbf'}
0.665 (+/-0.211) for {'random_state': 0, 'C': 0.1}
0.668 (+/-0.208) for {'solver': 'svd'}
0.613 (+/-0.156) for {'weights': 'distance', 'n_neighbors': 33, 'algorithm': 'ball_tree'}
0.616 (+/-0.130) for {'splitter': 'best', 'criterion': 'entropy', 'max_features': None, 'random_state': 0}
0.596 (+/-0.191) for {'priors': None}
0.659 (+/-0.241) for {'random_state': 0, 'alpha': 0.01, 'loss': 'log', 'epsilon': 0.01}
0.672 (+/-0.194) for {'criterion': 'entropy', 'max_features': 'sqrt', 'random_state': 0, 'n_estimators': 30}


III) REDUCCION DE DIMENSIONES
0.685 (+/-0.216) for {'random_state': 42, 'hidden_layer_sizes': (8, 4, 2), 'solver': 'adam', 'alpha': 1, 'activation': 'tanh', 'learning_rate': 'constant'}
0.683 (+/-0.205) for {'gamma': 0.01, 'random_state': 0, 'C': 1, 'kernel': 'rbf', 'probability': True}
0.670 (+/-0.238) for {'random_state': 0, 'C': 0.1}
0.666 (+/-0.240) for {'solver': 'svd'}
0.633 (+/-0.182) for {'weights': 'distance', 'n_neighbors': 33, 'algorithm': 'auto'}
0.610 (+/-0.125) for {'criterion': 'entropy', 'random_state': 0, 'max_features': None, 'splitter': 'random'}
0.631 (+/-0.212) for {'priors': None}
0.679 (+/-0.237) for {'alpha': 1, 'loss': 'modified_huber', 'random_state': 0, 'epsilon': 0.01}
0.679 (+/-0.188) for {'criterion': 'entropy', 'n_estimators': 30, 'random_state': 0, 'max_features': 'sqrt'}



IV) NORMALIZACION Y LUEGO REDUCCION
0.673 (+/-0.206) for {'activation': 'relu', 'learning_rate': 'constant', 'alpha': 1, 'hidden_layer_sizes': 12, 'random_state': 42, 'solver': 'adam'}
0.663 (+/-0.252) for {'probability': True, 'kernel': 'linear', 'gamma': 0.001, 'C': 1, 'random_state': 0}
0.664 (+/-0.239) for {'random_state': 0, 'C': 0.01}
0.666 (+/-0.240) for {'solver': 'svd'}
0.627 (+/-0.152) for {'algorithm': 'brute', 'n_neighbors': 33, 'weights': 'distance'}
0.611 (+/-0.124) for {'splitter': 'best', 'random_state': 0, 'max_features': None, 'criterion': 'entropy'}
0.627 (+/-0.207) for {'priors': None}
0.663 (+/-0.239) for {'epsilon': 0.01, 'random_state': 0, 'loss': 'log', 'alpha': 0.1}
0.679 (+/-0.187) for {'random_state': 0, 'n_estimators': 30, 'max_features': 'sqrt', 'criterion': 'entropy'}



Precision

I) NO NORMALIZACION Y NO REDUCCION
0.709 (+/-0.220) for {'solver': 'adam', 'activation': 'tanh', 'alpha': 1, 'random_state': 42, 'learning_rate': 'constant', 'hidden_layer_sizes': (8, 4, 2)}
0.702 (+/-0.301) for {'C': 0.001, 'probability': True, 'random_state': 0, 'gamma': 0.1, 'kernel': 'poly'}
0.688 (+/-0.234) for {'C': 0.1, 'random_state': 0}
0.699 (+/-0.218) for {'solver': 'svd'}
0.710 (+/-0.294) for {'weights': 'uniform', 'algorithm': 'brute', 'n_neighbors': 20}
0.616 (+/-0.129) for {'splitter': 'best', 'criterion': 'entropy', 'random_state': 0, 'max_features': None}
0.692 (+/-0.384) for {'priors': None}
0.691 (+/-0.253) for {'epsilon': 0.01, 'random_state': 0, 'alpha': 0.1, 'loss': 'modified_huber'}
0.689 (+/-0.225) for {'criterion': 'gini', 'random_state': 0, 'max_features': 'log2', 'n_estimators': 30}


II) NOMRALIZACION
0.690 (+/-0.273) for {'solver': 'adam', 'alpha': 10, 'learning_rate': 'constant', 'random_state': 42, 'hidden_layer_sizes': 12, 'activation': 'logistic'}
0.952 (+/-0.159) for {'gamma': 0.1, 'C': 1e-05, 'probability': True, 'kernel': 'poly', 'random_state': 0}
0.690 (+/-0.227) for {'C': 0.1, 'random_state': 0}
0.699 (+/-0.218) for {'solver': 'svd'}
0.719 (+/-0.255) for {'n_neighbors': 33, 'weights': 'distance', 'algorithm': 'ball_tree'}
0.616 (+/-0.126) for {'splitter': 'best', 'criterion': 'entropy', 'max_features': None, 'random_state': 0}
0.696 (+/-0.406) for {'priors': None}
0.705 (+/-0.329) for {'epsilon': 0.01, 'loss': 'log', 'alpha': 1, 'random_state': 0}
0.690 (+/-0.221) for {'random_state': 0, 'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 30}


III) REDUCCION DE DIMENSIONES
0.704 (+/-0.243) for {'activation': 'relu', 'alpha': 1, 'learning_rate': 'constant', 'random_state': 42, 'solver': 'adam', 'hidden_layer_sizes': (9, 3)}
0.710 (+/-0.278) for {'kernel': 'poly', 'random_state': 0, 'gamma': 0.1, 'probability': True, 'C': 0.01}
0.685 (+/-0.237) for {'random_state': 0, 'C': 0.1}
0.691 (+/-0.253) for {'solver': 'svd'}
0.706 (+/-0.255) for {'n_neighbors': 33, 'weights': 'distance', 'algorithm': 'ball_tree'}
0.612 (+/-0.112) for {'random_state': 0, 'criterion': 'entropy', 'splitter': 'best', 'max_features': None}
0.689 (+/-0.249) for {'priors': None}
0.687 (+/-0.327) for {'loss': 'log', 'epsilon': 0.01, 'alpha': 0.001, 'random_state': 0}
0.689 (+/-0.191) for {'random_state': 0, 'criterion': 'entropy', 'n_estimators': 30, 'max_features': 'sqrt'}


IV) NORMALIZACION Y LUEGO REDUCCION
0.840 (+/-0.337) for {'random_state': 42, 'hidden_layer_sizes': 12, 'alpha': 100, 'solver': 'adam', 'activation': 'relu', 'learning_rate': 'constant'}
0.868 (+/-0.599) for {'probability': True, 'gamma': 0.1, 'random_state': 0, 'kernel': 'poly', 'C': 0.0001}
0.687 (+/-0.230) for {'random_state': 0, 'C': 0.01}
0.691 (+/-0.253) for {'solver': 'svd'}
0.712 (+/-0.220) for {'n_neighbors': 33, 'algorithm': 'auto', 'weights': 'distance'}
0.614 (+/-0.112) for {'max_features': None, 'random_state': 0, 'criterion': 'entropy', 'splitter': 'best'}
0.687 (+/-0.247) for {'priors': None}
0.691 (+/-0.331) for {'alpha': 1, 'random_state': 0, 'epsilon': 0.01, 'loss': 'log'}
0.690 (+/-0.183) for {'max_features': 'log2', 'random_state': 0, 'criterion': 'gini', 'n_estimators': 20}



Recall

I) NO NORMALIZACION Y NO REDUCCION
1.000 (+/-0.000) for {'solver': 'adam', 'alpha': 0.1, 'random_state': 42, 'activation': 'logistic', 'hidden_layer_sizes': (8, 4, 2), 'learning_rate': 'constant'}
0.989 (+/-0.047) for {'C': 1e-05, 'probability': True, 'random_state': 0, 'kernel': 'linear', 'gamma': 0.001}
0.682 (+/-0.288) for {'C': 0.001, 'random_state': 0}
0.578 (+/-0.302) for {'solver': 'svd'}
0.452 (+/-0.272) for {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'auto'}
0.614 (+/-0.186) for {'random_state': 0, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}
0.323 (+/-0.379) for {'priors': None}
0.715 (+/-0.343) for {'alpha': 1, 'random_state': 0, 'epsilon': 0.01, 'loss': 'log'}
0.668 (+/-0.239) for {'random_state': 0, 'max_features': None, 'criterion': 'gini', 'n_estimators': 25}



II) NOMRALIZACION
1.000 (+/-0.000) for {'hidden_layer_sizes': (8, 4, 2), 'random_state': 42, 'learning_rate': 'constant', 'alpha': 1, 'activation': 'logistic', 'solver': 'adam'}
0.913 (+/-0.161) for {'gamma': 0.1, 'random_state': 0, 'C': 1e-05, 'kernel': 'rbf', 'probability': True}
0.602 (+/-0.285) for {'C': 1, 'random_state': 0}
0.578 (+/-0.302) for {'solver': 'svd'}
0.459 (+/-0.202) for {'n_neighbors': 5, 'algorithm': 'brute', 'weights': 'uniform'}
0.615 (+/-0.189) for {'criterion': 'entropy', 'random_state': 0, 'max_features': None, 'splitter': 'best'}
0.270 (+/-0.362) for {'priors': None}
0.620 (+/-0.347) for {'random_state': 0, 'alpha': 0.0001, 'loss': 'modified_huber', 'epsilon': 0.01}
0.667 (+/-0.242) for {'criterion': 'gini', 'random_state': 0, 'max_features': None, 'n_estimators': 25}


III) REDUCCION DE DIMENSIONES
1.000 (+/-0.000) for {'hidden_layer_sizes': (9, 3), 'alpha': 10, 'learning_rate': 'constant', 'activation': 'logistic', 'solver': 'adam', 'random_state': 42}
0.990 (+/-0.037) for {'C': 1e-05, 'random_state': 0, 'kernel': 'linear', 'gamma': 0.001, 'probability': True}
0.679 (+/-0.292) for {'C': 0.001, 'random_state': 0}
0.589 (+/-0.338) for {'solver': 'svd'}
0.496 (+/-0.260) for {'weights': 'uniform', 'algorithm': 'ball_tree', 'n_neighbors': 5}
0.607 (+/-0.228) for {'max_features': None, 'random_state': 0, 'splitter': 'random', 'criterion': 'entropy'}
0.426 (+/-0.401) for {'priors': None}
0.720 (+/-0.348) for {'loss': 'log', 'alpha': 1, 'random_state': 0, 'epsilon': 0.01}
0.663 (+/-0.259) for {'max_features': 'sqrt', 'n_estimators': 25, 'random_state': 0, 'criterion': 'entropy'}



IV) NORMALIZACION Y LUEGO REDUCCION
1.000 (+/-0.000) for {'alpha': 10, 'hidden_layer_sizes': (9, 3), 'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'adam', 'random_state': 42}
0.911 (+/-0.163) for {'kernel': 'rbf', 'C': 1e-05, 'gamma': 0.1, 'probability': True, 'random_state': 0}
0.608 (+/-0.334) for {'C': 10, 'random_state': 0}
0.589 (+/-0.338) for {'solver': 'svd'}
0.490 (+/-0.237) for {'weights': 'distance', 'n_neighbors': 5, 'algorithm': 'brute'}
0.607 (+/-0.228) for {'max_features': None, 'splitter': 'random', 'random_state': 0, 'criterion': 'entropy'}
0.418 (+/-0.387) for {'priors': None}
0.653 (+/-0.351) for {'alpha': 0.0001, 'loss': 'modified_huber', 'epsilon': 0.01, 'random_state': 0}
0.661 (+/-0.263) for {'max_features': 'sqrt', 'n_estimators': 25, 'random_state': 0, 'criterion': 'entropy'}













