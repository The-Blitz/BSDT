Orden:
MLPClassifier,SVM,LogisticRegression,LinearDiscriminantAnalysis,KNeighborsClassifier,DecisionTreeClassifier,GaussianNB,SGDClassifier,RandomForestClassifier

Accuracy

I) NO NORMALIZACION Y NO REDUCCION
0.792 (+/-0.103) for {'solver': 'adam', 'hidden_layer_sizes': (8, 4, 2), 'random_state': 42, 'activation': 'relu', 'alpha': 0.1, 'learning_rate': 'constant'}
0.777 (+/-0.091) for {'probability': True, 'random_state': 0, 'gamma': 0.1, 'C': 1, 'kernel': 'rbf'}
0.777 (+/-0.104) for {'C': 1, 'random_state': 0}
0.785 (+/-0.081) for {'solver': 'svd'}
0.677 (+/-0.119) for {'weights': 'distance', 'algorithm': 'brute', 'n_neighbors': 5}
0.713 (+/-0.096) for {'max_features': 'sqrt', 'criterion': 'gini', 'splitter': 'best', 'random_state': 0}
0.600 (+/-0.102) for {'priors': None}
0.762 (+/-0.096) for {'loss': 'log', 'epsilon': 0.01, 'alpha': 0.1, 'random_state': 0}
0.752 (+/-0.131) for {'n_estimators': 15, 'max_features': 'log2', 'criterion': 'gini', 'random_state': 0}


II) NOMRALIZACION
0.782 (+/-0.092) for {'activation': 'logistic', 'hidden_layer_sizes': 12, 'alpha': 0.1, 'solver': 'adam', 'learning_rate': 'constant', 'random_state': 42}
0.760 (+/-0.108) for {'probability': True, 'gamma': 0.001, 'kernel': 'linear', 'random_state': 0, 'C': 0.01}
0.782 (+/-0.055) for {'random_state': 0, 'C': 1}
0.785 (+/-0.081) for {'solver': 'svd'}
0.680 (+/-0.145) for {'n_neighbors': 5, 'algorithm': 'auto', 'weights': 'distance'}
0.713 (+/-0.096) for {'criterion': 'gini', 'splitter': 'best', 'random_state': 0, 'max_features': 'sqrt'}
0.600 (+/-0.100) for {'priors': None}
0.777 (+/-0.117) for {'loss': 'log', 'epsilon': 0.01, 'alpha': 0.1, 'random_state': 0}
0.757 (+/-0.127) for {'criterion': 'gini', 'random_state': 0, 'n_estimators': 15, 'max_features': 'log2'}


III) REDUCCION DE DIMENSIONES
0.790 (+/-0.117) for {'solver': 'adam', 'alpha': 1, 'learning_rate': 'constant', 'random_state': 42, 'activation': 'relu', 'hidden_layer_sizes': 12}
0.765 (+/-0.112) for {'probability': True, 'kernel': 'linear', 'C': 1, 'random_state': 0, 'gamma': 0.001}
0.782 (+/-0.121) for {'C': 100, 'random_state': 0}
0.765 (+/-0.105) for {'solver': 'svd'}
0.688 (+/-0.096) for {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute'}
0.710 (+/-0.142) for {'random_state': 0, 'criterion': 'entropy', 'max_features': 'sqrt', 'splitter': 'best'}
0.675 (+/-0.155) for {'priors': None}
0.767 (+/-0.112) for {'loss': 'modified_huber', 'random_state': 0, 'alpha': 0.0001, 'epsilon': 0.01}
0.750 (+/-0.147) for {'random_state': 0, 'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 5}


IV) NORMALIZACION Y LUEGO REDUCCION
0.790 (+/-0.140) for {'activation': 'tanh', 'random_state': 42, 'learning_rate': 'constant', 'hidden_layer_sizes': 12, 'alpha': 0.01, 'solver': 'adam'}
0.780 (+/-0.124) for {'C': 1, 'random_state': 0, 'gamma': 0.01, 'probability': True, 'kernel': 'rbf'}
0.782 (+/-0.140) for {'C': 0.01, 'random_state': 0}
0.765 (+/-0.105) for {'solver': 'svd'}
0.708 (+/-0.132) for {'n_neighbors': 5, 'algorithm': 'auto', 'weights': 'uniform'}
0.713 (+/-0.150) for {'random_state': 0, 'splitter': 'best', 'max_features': 'sqrt', 'criterion': 'entropy'}
0.642 (+/-0.107) for {'priors': None}
0.782 (+/-0.125) for {'alpha': 1, 'random_state': 0, 'loss': 'log', 'epsilon': 0.01}
0.757 (+/-0.158) for {'random_state': 0, 'n_estimators': 5, 'max_features': 'sqrt', 'criterion': 'gini'}



Precision

I) NO NORMALIZACION Y NO REDUCCION
0.892 (+/-0.214) for {'hidden_layer_sizes': (9, 3), 'random_state': 42, 'alpha': 10, 'learning_rate': 'constant', 'activation': 'relu', 'solver': 'adam'}
0.870 (+/-0.207) for {'kernel': 'poly', 'gamma': 0.1, 'C': 1, 'probability': True, 'random_state': 0}
0.833 (+/-0.164) for {'random_state': 0, 'C': 1}
0.840 (+/-0.113) for {'solver': 'svd'}
0.914 (+/-0.143) for {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'}
0.740 (+/-0.233) for {'random_state': 0, 'max_features': None, 'splitter': 'best', 'criterion': 'entropy'}
0.782 (+/-0.302) for {'priors': None}
0.871 (+/-0.203) for {'random_state': 0, 'alpha': 0.01, 'loss': 'log', 'epsilon': 0.01}
0.809 (+/-0.179) for {'n_estimators': 30, 'random_state': 0, 'max_features': 'sqrt', 'criterion': 'gini'}


II) NOMRALIZACION
0.889 (+/-0.183) for {'hidden_layer_sizes': (9, 3), 'alpha': 1, 'activation': 'logistic', 'solver': 'adam', 'random_state': 42, 'learning_rate': 'constant'}
0.943 (+/-0.229) for {'gamma': 0.001, 'C': 1e-05, 'probability': True, 'random_state': 0, 'kernel': 'linear'}
0.843 (+/-0.182) for {'C': 0.001, 'random_state': 0}
0.840 (+/-0.113) for {'solver': 'svd'}
0.940 (+/-0.211) for {'n_neighbors': 15, 'algorithm': 'ball_tree', 'weights': 'uniform'}
0.740 (+/-0.233) for {'max_features': None, 'random_state': 0, 'criterion': 'entropy', 'splitter': 'best'}
0.791 (+/-0.293) for {'priors': None}
0.818 (+/-0.180) for {'alpha': 0.1, 'random_state': 0, 'epsilon': 0.01, 'loss': 'log'}
0.811 (+/-0.136) for {'max_features': 'sqrt', 'n_estimators': 10, 'criterion': 'entropy', 'random_state': 0}


III) REDUCCION DE DIMENSIONES
0.889 (+/-0.250) for {'activation': 'logistic', 'solver': 'adam', 'learning_rate': 'constant', 'random_state': 42, 'alpha': 1, 'hidden_layer_sizes': (9, 3)}
0.863 (+/-0.234) for {'random_state': 0, 'probability': True, 'gamma': 0.1, 'C': 1, 'kernel': 'poly'}
0.841 (+/-0.208) for {'random_state': 0, 'C': 1}
0.829 (+/-0.191) for {'solver': 'svd'}
0.904 (+/-0.238) for {'weights': 'uniform', 'algorithm': 'auto', 'n_neighbors': 20}
0.728 (+/-0.150) for {'random_state': 0, 'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt'}
0.872 (+/-0.259) for {'priors': None}
0.869 (+/-0.232) for {'random_state': 0, 'loss': 'modified_huber', 'alpha': 0.1, 'epsilon': 0.01}
0.784 (+/-0.211) for {'random_state': 0, 'criterion': 'entropy', 'n_estimators': 10, 'max_features': 'sqrt'}


IV) NORMALIZACION Y LUEGO REDUCCION

0.858 (+/-0.210) for {'random_state': 42, 'activation': 'tanh', 'hidden_layer_sizes': (8, 4, 2), 'solver': 'adam', 'learning_rate': 'constant', 'alpha': 10}
0.927 (+/-0.208) for {'random_state': 0, 'C': 0.001, 'kernel': 'linear', 'probability': True, 'gamma': 0.001}
0.856 (+/-0.235) for {'random_state': 0, 'C': 0.01}
0.829 (+/-0.191) for {'solver': 'svd'}
0.923 (+/-0.212) for {'n_neighbors': 33, 'weights': 'uniform', 'algorithm': 'auto'}
0.729 (+/-0.150) for {'random_state': 0, 'max_features': 'sqrt', 'splitter': 'best', 'criterion': 'entropy'}
0.869 (+/-0.260) for {'priors': None}
0.830 (+/-0.219) for {'epsilon': 0.01, 'random_state': 0, 'loss': 'modified_huber', 'alpha': 1}
0.789 (+/-0.209) for {'random_state': 0, 'max_features': 'sqrt', 'n_estimators': 10, 'criterion': 'gini'}


Recall

I) NO NORMALIZACION Y NO REDUCCION
1.000 (+/-0.000) for {'solver': 'adam', 'hidden_layer_sizes': 12, 'learning_rate': 'constant', 'alpha': 100, 'activation': 'logistic', 'random_state': 42}
0.980 (+/-0.066) for {'C': 0.01, 'kernel': 'poly', 'probability': True, 'gamma': 0.1, 'random_state': 0}
0.740 (+/-0.108) for {'C': 1000, 'random_state': 0}
0.710 (+/-0.160) for {'solver': 'svd'}
0.450 (+/-0.214) for {'n_neighbors': 5, 'algorithm': 'brute', 'weights': 'uniform'}
0.690 (+/-0.140) for {'criterion': 'gini', 'max_features': 'sqrt', 'splitter': 'best', 'random_state': 0}
0.285 (+/-0.215) for {'priors': None}
0.840 (+/-0.133) for {'epsilon': 0.01, 'alpha': 1, 'loss': 'log', 'random_state': 0}
0.700 (+/-0.195) for {'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 25, 'random_state': 0}


II) NOMRALIZACION
1.000 (+/-0.000) for {'random_state': 42, 'activation': 'logistic', 'solver': 'adam', 'hidden_layer_sizes': 12, 'alpha': 100, 'learning_rate': 'constant'}
0.945 (+/-0.083) for {'random_state': 0, 'kernel': 'rbf', 'C': 1e-05, 'gamma': 0.1, 'probability': True}
0.730 (+/-0.092) for {'random_state': 0, 'C': 100}
0.710 (+/-0.160) for {'solver': 'svd'}
0.490 (+/-0.260) for {'weights': 'distance', 'algorithm': 'brute', 'n_neighbors': 5}
0.690 (+/-0.140) for {'criterion': 'gini', 'random_state': 0, 'splitter': 'best', 'max_features': 'sqrt'}
0.280 (+/-0.220) for {'priors': None}
0.775 (+/-0.206) for {'epsilon': 0.01, 'random_state': 0, 'alpha': 1, 'loss': 'log'}
0.710 (+/-0.194) for {'criterion': 'entropy', 'n_estimators': 25, 'random_state': 0, 'max_features': 'log2'}


III) REDUCCION DE DIMENSIONES
1.000 (+/-0.000) for {'activation': 'logistic', 'random_state': 42, 'alpha': 1, 'hidden_layer_sizes': (8, 4, 2), 'solver': 'adam', 'learning_rate': 'constant'}
0.980 (+/-0.066) for {'gamma': 0.1, 'kernel': 'poly', 'probability': True, 'random_state': 0, 'C': 0.01}
0.725 (+/-0.143) for {'random_state': 0, 'C': 0.1}
0.685 (+/-0.173) for {'solver': 'svd'}
0.495 (+/-0.212) for {'algorithm': 'brute', 'n_neighbors': 5, 'weights': 'uniform'}
0.700 (+/-0.210) for {'max_features': None, 'random_state': 0, 'splitter': 'random', 'criterion': 'gini'}
0.415 (+/-0.290) for {'priors': None}
0.835 (+/-0.135) for {'alpha': 1, 'loss': 'log', 'epsilon': 0.01, 'random_state': 0}
0.740 (+/-0.189) for {'max_features': 'sqrt', 'random_state': 0, 'n_estimators': 5, 'criterion': 'gini'}


IV) NORMALIZACION Y LUEGO REDUCCION
1.000 (+/-0.000) for {'alpha': 1, 'learning_rate': 'constant', 'random_state': 42, 'hidden_layer_sizes': (8, 4, 2), 'activation': 'logistic', 'solver': 'adam'}
0.900 (+/-0.045) for {'random_state': 0, 'C': 1e-05, 'gamma': 0.1, 'probability': True, 'kernel': 'rbf'}
0.725 (+/-0.150) for {'C': 1, 'random_state': 0}
0.685 (+/-0.173) for {'solver': 'svd'}
0.590 (+/-0.178) for {'n_neighbors': 5, 'algorithm': 'brute', 'weights': 'distance'}
0.700 (+/-0.210) for {'max_features': None, 'criterion': 'gini', 'random_state': 0, 'splitter': 'random'}
0.340 (+/-0.204) for {'priors': None}
0.745 (+/-0.176) for {'epsilon': 0.01, 'loss': 'log', 'alpha': 1, 'random_state': 0}
0.745 (+/-0.192) for {'max_features': 'sqrt', 'criterion': 'gini', 'random_state': 0, 'n_estimators': 5}






