Orden:
MLPClassifier,SVM,LogisticRegression,LinearDiscriminantAnalysis,KNeighborsClassifier,DecisionTreeClassifier,GaussianNB,SGDClassifier,RandomForestClassifier

Accuracy

I) NO NORMALIZACION Y NO REDUCCION
0.838 (+/-0.127) for {'random_state': 42, 'alpha': 10, 'learning_rate': 'constant', 'hidden_layer_sizes': 12, 'solver': 'adam', 'activation': 'relu'}
0.835 (+/-0.100) for {'probability': True, 'random_state': 0, 'kernel': 'rbf', 'gamma': 0.01, 'C': 1}
0.838 (+/-0.138) for {'random_state': 0, 'C': 0.1}
0.780 (+/-0.062) for {'solver': 'svd'}
0.792 (+/-0.112) for {'weights': 'uniform', 'n_neighbors': 9, 'algorithm': 'auto'}
0.800 (+/-0.132) for {'splitter': 'best', 'max_features': None, 'random_state': 0, 'criterion': 'entropy'}
0.618 (+/-0.114) for {'priors': None}
0.825 (+/-0.134) for {'epsilon': 0.01, 'random_state': 0, 'alpha': 1, 'loss': 'modified_huber'}
0.835 (+/-0.123) for {'max_features': 'sqrt', 'random_state': 0, 'n_estimators': 30, 'criterion': 'entropy'}


II) NOMRALIZACION
0.812 (+/-0.096) for {'hidden_layer_sizes': 12, 'alpha': 100, 'learning_rate': 'constant', 'solver': 'adam', 'activation': 'relu', 'random_state': 42}
0.807 (+/-0.123) for {'C': 1, 'probability': True, 'random_state': 0, 'kernel': 'linear', 'gamma': 0.001}
0.805 (+/-0.083) for {'C': 0.001, 'random_state': 0}
0.780 (+/-0.062) for {'solver': 'svd'}
0.728 (+/-0.149) for {'n_neighbors': 5, 'algorithm': 'auto', 'weights': 'uniform'}
0.800 (+/-0.132) for {'splitter': 'best', 'criterion': 'entropy', 'max_features': None, 'random_state': 0}
0.615 (+/-0.105) for {'priors': None}
0.802 (+/-0.072) for {'loss': 'log', 'alpha': 0.1, 'epsilon': 0.01, 'random_state': 0}
0.835 (+/-0.125) for {'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 30, 'random_state': 0}


III) REDUCCION DE DIMENSIONES
0.850 (+/-0.120) for {'random_state': 42, 'solver': 'adam', 'learning_rate': 'constant', 'activation': 'tanh', 'hidden_layer_sizes': 12, 'alpha': 10}
0.838 (+/-0.108) for {'gamma': 0.01, 'C': 1, 'random_state': 0, 'kernel': 'rbf', 'probability': True}
0.843 (+/-0.130) for {'C': 0.1, 'random_state': 0}
0.802 (+/-0.104) for {'solver': 'svd'}
0.792 (+/-0.129) for {'algorithm': 'auto', 'n_neighbors': 9, 'weights': 'uniform'}
0.782 (+/-0.105) for {'splitter': 'best', 'criterion': 'entropy', 'max_features': None, 'random_state': 0}
0.782 (+/-0.100) for {'priors': None}
0.823 (+/-0.123) for {'epsilon': 0.01, 'random_state': 0, 'alpha': 1, 'loss': 'modified_huber'}
0.843 (+/-0.143) for {'random_state': 0, 'criterion': 'gini', 'max_features': None, 'n_estimators': 15}


IV) NORMALIZACION Y LUEGO REDUCCION
0.830 (+/-0.151) for {'learning_rate': 'constant', 'hidden_layer_sizes': (9, 3), 'solver': 'adam', 'alpha': 0.1, 'random_state': 42, 'activation': 'tanh'}
0.825 (+/-0.116) for {'probability': True, 'C': 1, 'random_state': 0, 'kernel': 'rbf', 'gamma': 0.01}
0.820 (+/-0.111) for {'C': 10, 'random_state': 0}
0.802 (+/-0.104) for {'solver': 'svd'}
0.755 (+/-0.132) for {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'auto'}
0.782 (+/-0.105) for {'random_state': 0, 'max_features': None, 'criterion': 'entropy', 'splitter': 'best'}
0.772 (+/-0.111) for {'priors': None}
0.825 (+/-0.114) for {'random_state': 0, 'epsilon': 0.01, 'loss': 'log', 'alpha': 0.1}
0.843 (+/-0.143) for {'random_state': 0, 'max_features': None, 'criterion': 'gini', 'n_estimators': 15}


Precision

I) NO NORMALIZACION Y NO REDUCCION
0.941 (+/-0.161) for {'hidden_layer_sizes': (9, 3), 'learning_rate': 'constant', 'solver': 'adam', 'activation': 'tanh', 'random_state': 42, 'alpha': 100}
0.893 (+/-0.151) for {'random_state': 0, 'kernel': 'rbf', 'probability': True, 'gamma': 0.01, 'C': 1}
0.868 (+/-0.190) for {'random_state': 0, 'C': 0.1}
0.838 (+/-0.140) for {'solver': 'svd'}
0.933 (+/-0.119) for {'algorithm': 'ball_tree', 'n_neighbors': 9, 'weights': 'uniform'}
0.809 (+/-0.178) for {'criterion': 'gini', 'max_features': None, 'splitter': 'best', 'random_state': 0}
0.796 (+/-0.279) for {'priors': None}
0.902 (+/-0.179) for {'random_state': 0, 'epsilon': 0.01, 'alpha': 0.0001, 'loss': 'modified_huber'}
0.862 (+/-0.200) for {'criterion': 'entropy', 'max_features': 'log2', 'random_state': 0, 'n_estimators': 30}


II) NOMRALIZACION
0.929 (+/-0.209) for {'activation': 'tanh', 'alpha': 100, 'solver': 'adam', 'hidden_layer_sizes': (9, 3), 'random_state': 42, 'learning_rate': 'constant'}
0.943 (+/-0.190) for {'kernel': 'linear', 'C': 1e-05, 'gamma': 0.001, 'random_state': 0, 'probability': True}
0.873 (+/-0.158) for {'C': 0.001, 'random_state': 0}
0.838 (+/-0.140) for {'solver': 'svd'}
0.983 (+/-0.100) for {'n_neighbors': 25, 'weights': 'uniform', 'algorithm': 'auto'}
0.812 (+/-0.175) for {'splitter': 'best', 'criterion': 'gini', 'max_features': None, 'random_state': 0}
0.811 (+/-0.276) for {'priors': None}
0.839 (+/-0.148) for {'loss': 'modified_huber', 'random_state': 0, 'alpha': 1, 'epsilon': 0.01}
0.866 (+/-0.201) for {'criterion': 'entropy', 'max_features': 'log2', 'random_state': 0, 'n_estimators': 30}


III) REDUCCION DE DIMENSIONES
0.882 (+/-0.179) for {'solver': 'adam', 'alpha': 10, 'activation': 'tanh', 'hidden_layer_sizes': 12, 'learning_rate': 'constant', 'random_state': 42}
0.894 (+/-0.169) for {'kernel': 'rbf', 'C': 1, 'random_state': 0, 'probability': True, 'gamma': 0.01}
0.878 (+/-0.194) for {'C': 0.1, 'random_state': 0}
0.855 (+/-0.164) for {'solver': 'svd'}
0.921 (+/-0.132) for {'weights': 'distance', 'n_neighbors': 20, 'algorithm': 'auto'}
0.802 (+/-0.134) for {'splitter': 'best', 'criterion': 'gini', 'max_features': 'sqrt', 'random_state': 0}
0.892 (+/-0.164) for {'priors': None}
0.900 (+/-0.184) for {'loss': 'modified_huber', 'epsilon': 0.01, 'alpha': 0.1, 'random_state': 0}
0.872 (+/-0.170) for {'n_estimators': 10, 'criterion': 'gini', 'max_features': None, 'random_state': 0}


IV) NORMALIZACION Y LUEGO REDUCCION
0.874 (+/-0.184) for {'solver': 'adam', 'activation': 'logistic', 'alpha': 10, 'hidden_layer_sizes': 12, 'learning_rate': 'constant', 'random_state': 42}
0.952 (+/-0.154) for {'C': 1e-05, 'kernel': 'linear', 'probability': True, 'gamma': 0.001, 'random_state': 0}
0.888 (+/-0.175) for {'C': 0.01, 'random_state': 0}
0.855 (+/-0.164) for {'solver': 'svd'}
0.952 (+/-0.172) for {'n_neighbors': 33, 'weights': 'uniform', 'algorithm': 'auto'}
0.802 (+/-0.134) for {'criterion': 'gini', 'max_features': 'sqrt', 'splitter': 'best', 'random_state': 0}
0.898 (+/-0.178) for {'priors': None}
0.881 (+/-0.200) for {'loss': 'modified_huber', 'random_state': 0, 'epsilon': 0.01, 'alpha': 1}
0.872 (+/-0.170) for {'criterion': 'gini', 'random_state': 0, 'max_features': None, 'n_estimators': 10}


Recall

I) NO NORMALIZACION Y NO REDUCCION
1.000 (+/-0.000) for {'solver': 'adam', 'activation': 'logistic', 'random_state': 42, 'alpha': 0.01, 'hidden_layer_sizes': (8, 4, 2), 'learning_rate': 'constant'}
0.995 (+/-0.030) for {'random_state': 0, 'gamma': 0.001, 'kernel': 'poly', 'C': 1e-05, 'probability': True}
0.825 (+/-0.143) for {'random_state': 0, 'C': 0.01}
0.710 (+/-0.189) for {'solver': 'svd'}
0.635 (+/-0.168) for {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'auto'}
0.810 (+/-0.154) for {'random_state': 0, 'criterion': 'entropy', 'max_features': None, 'splitter': 'best'}
0.325 (+/-0.266) for {'priors': None}
0.825 (+/-0.150) for {'loss': 'log', 'random_state': 0, 'alpha': 1, 'epsilon': 0.01}
0.830 (+/-0.156) for {'random_state': 0, 'criterion': 'gini', 'n_estimators': 25, 'max_features': 'log2'}


II) NOMRALIZACION
1.000 (+/-0.000) for {'alpha': 0.01, 'random_state': 42, 'hidden_layer_sizes': (8, 4, 2), 'activation': 'logistic', 'solver': 'adam', 'learning_rate': 'constant'}
0.980 (+/-0.049) for {'random_state': 0, 'gamma': 0.1, 'kernel': 'rbf', 'C': 1e-05, 'probability': True}
0.775 (+/-0.150) for {'random_state': 0, 'C': 1}
0.710 (+/-0.189) for {'solver': 'svd'}
0.535 (+/-0.257) for {'algorithm': 'auto', 'weights': 'uniform', 'n_neighbors': 5}
0.810 (+/-0.154) for {'random_state': 0, 'max_features': None, 'splitter': 'best', 'criterion': 'entropy'}
0.310 (+/-0.244) for {'priors': None}
0.800 (+/-0.179) for {'alpha': 0.01, 'random_state': 0, 'epsilon': 0.01, 'loss': 'log'}
0.830 (+/-0.156) for {'random_state': 0, 'max_features': 'log2', 'n_estimators': 15, 'criterion': 'entropy'}


III) REDUCCION DE DIMENSIONES
1.000 (+/-0.000) for {'activation': 'logistic', 'learning_rate': 'constant', 'random_state': 42, 'hidden_layer_sizes': (8, 4, 2), 'solver': 'adam', 'alpha': 1}
0.995 (+/-0.030) for {'C': 1e-05, 'probability': True, 'gamma': 0.001, 'random_state': 0, 'kernel': 'poly'}
0.830 (+/-0.143) for {'C': 0.01, 'random_state': 0}
0.740 (+/-0.183) for {'solver': 'svd'}
0.655 (+/-0.145) for {'weights': 'uniform', 'n_neighbors': 5, 'algorithm': 'auto'}
0.775 (+/-0.163) for {'max_features': None, 'criterion': 'gini', 'splitter': 'best', 'random_state': 0}
0.655 (+/-0.234) for {'priors': None}
0.830 (+/-0.143) for {'loss': 'log', 'random_state': 0, 'epsilon': 0.01, 'alpha': 1}
0.830 (+/-0.162) for {'max_features': None, 'criterion': 'gini', 'random_state': 0, 'n_estimators': 15}


IV) NORMALIZACION Y LUEGO REDUCCION
1.000 (+/-0.000) for {'activation': 'logistic', 'solver': 'adam', 'learning_rate': 'constant', 'hidden_layer_sizes': (8, 4, 2), 'random_state': 42, 'alpha': 1}
0.970 (+/-0.066) for {'gamma': 0.1, 'C': 1e-05, 'kernel': 'rbf', 'probability': True, 'random_state': 0}
0.795 (+/-0.151) for {'C': 10, 'random_state': 0}
0.740 (+/-0.183) for {'solver': 'svd'}
0.600 (+/-0.184) for {'algorithm': 'auto', 'weights': 'uniform', 'n_neighbors': 5}
0.770 (+/-0.143) for {'criterion': 'gini', 'max_features': None, 'random_state': 0, 'splitter': 'best'}
0.625 (+/-0.211) for {'priors': None}
0.800 (+/-0.195) for {'epsilon': 0.01, 'random_state': 0, 'loss': 'modified_huber', 'alpha': 0.001}
0.830 (+/-0.162) for {'criterion': 'gini', 'max_features': None, 'random_state': 0, 'n_estimators': 15}













